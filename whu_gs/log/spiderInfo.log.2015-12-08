Mon, 07 Dec 2015 14:47:57 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:04:14 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:04:57 logstats.py[line:47] INFO Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:06:04 logstats.py[line:47] INFO Crawled 7 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:12:35 logstats.py[line:47] INFO Crawled 7 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:22:27 logstats.py[line:47] INFO Crawled 7 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:22:57 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:26:01 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:27:09 logstats.py[line:47] INFO Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:29:46 logstats.py[line:47] INFO Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:32:33 logstats.py[line:47] INFO Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:40:06 logstats.py[line:47] INFO Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:40:39 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:41:49 logstats.py[line:47] INFO Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:42:49 logstats.py[line:47] INFO Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:44:25 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:45:29 logstats.py[line:47] INFO Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:57:41 logstats.py[line:47] INFO Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:57:53 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/exception_count': 5,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'downloader/request_bytes': 1659,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 10215,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2015, 12, 7, 7, 57, 53, 208517),
 'log_count/DEBUG': 8,
 'log_count/INFO': 3,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 7, 7, 44, 25, 622838)}
Mon, 07 Dec 2015 15:57:55 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 15:59:18 logstats.py[line:47] INFO Crawled 10 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:00:30 logstats.py[line:47] INFO Crawled 13 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:27:13 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:28:13 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:28:42 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 3,
 'downloader/request_bytes': 687,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 7, 8, 28, 42, 842622),
 'log_count/DEBUG': 4,
 'log_count/INFO': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2015, 12, 7, 8, 27, 13, 762887)}
Mon, 07 Dec 2015 16:29:17 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:30:24 logstats.py[line:47] INFO Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:32:41 logstats.py[line:47] INFO Crawled 14 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:32:43 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 4,
 'downloader/request_bytes': 5663,
 'downloader/request_count': 20,
 'downloader/request_method_count/GET': 20,
 'downloader/response_bytes': 304196,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 7, 8, 32, 43, 860350),
 'log_count/DEBUG': 22,
 'log_count/INFO': 3,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 20,
 'scheduler/dequeued/memory': 20,
 'scheduler/enqueued': 20,
 'scheduler/enqueued/memory': 20,
 'spider_exceptions/IndexError': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 7, 8, 29, 17, 61066)}
Mon, 07 Dec 2015 16:35:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:35:04 _legacy.py[line:154] CRITICAL Unhandled Error
Traceback (most recent call last):
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/crawler.py", line 251, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 1194, in run
    self.mainLoop()
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 1203, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 825, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/core/engine.py", line 118, in _next_request
    self.crawl(request, spider)
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/core/engine.py", line 180, in crawl
    assert spider in self.open_spiders, \
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/core/engine.py", line 173, in open_spiders
    return [selelf.spider] if self.spider else []
exceptions.NameError: global name 'self' is not defined

Mon, 07 Dec 2015 16:35:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:35:32 _legacy.py[line:154] CRITICAL Unhandled Error
Traceback (most recent call last):
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/commands/crawl.py", line 58, in run
    self.crawler_process.start()
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/crawler.py", line 251, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 1194, in run
    self.mainLoop()
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 1203, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/base.py", line 825, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/utils/reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/core/engine.py", line 118, in _next_request
    self.crawl(request, spider)
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/core/engine.py", line 180, in crawl
    assert spider in self.open_spiders, \
  File "/home/zhangrui/whu_gs/whu_gs/scrapy/core/engine.py", line 173, in open_spiders
    return [self.spider] if self.spider else []
exceptions.NameError: global name 'self' is not defined

Mon, 07 Dec 2015 16:35:48 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:35:48 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10271,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 7, 8, 35, 48, 785450),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeDecodeError': 1,
 'start_time': datetime.datetime(2015, 12, 7, 8, 35, 48, 407439)}
Mon, 07 Dec 2015 16:36:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:36:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:37:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:37:19 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:37:19 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10271,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 7, 8, 37, 19, 295361),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeDecodeError': 1,
 'start_time': datetime.datetime(2015, 12, 7, 8, 37, 19, 127476)}
Mon, 07 Dec 2015 16:37:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:38:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:38:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:39:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:39:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:40:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:40:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:41:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:41:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:42:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:42:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:43:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:43:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:44:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:44:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:45:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:45:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:46:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:46:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:47:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:47:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:48:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:48:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:49:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:49:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:50:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:50:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:51:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:51:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:52:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:52:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:53:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:53:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:54:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:54:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:55:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:55:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:56:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:56:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:57:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:57:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:58:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:58:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:59:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 16:59:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:00:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:00:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:01:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:01:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:02:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:02:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:03:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:03:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:04:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:04:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:05:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:05:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:06:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:06:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:07:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:07:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:08:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:08:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:09:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:09:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:10:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:10:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:11:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:11:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:12:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:12:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:13:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:13:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:14:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:14:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:15:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:15:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:16:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:16:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:17:04 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:17:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:18:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Mon, 07 Dec 2015 17:18:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 08 Dec 2015 17:01:59 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 08 Dec 2015 17:02:59 logstats.py[line:47] INFO Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
Tue, 08 Dec 2015 17:41:09 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 08 Dec 2015 17:41:09 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10121,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 8, 9, 41, 9, 291039),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/UnicodeDecodeError': 1,
 'start_time': datetime.datetime(2015, 12, 8, 9, 41, 9, 81604)}
Tue, 08 Dec 2015 17:47:49 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
