Tue, 29 Mar 2016 14:34:38 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 14:34:51 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 18072,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 1254757,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 6, 34, 51, 631912),
 'log_count/DEBUG': 53,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued': 52,
 'scheduler/dequeued/memory': 52,
 'scheduler/enqueued': 52,
 'scheduler/enqueued/memory': 52,
 'spider_exceptions/IndexError': 4,
 'start_time': datetime.datetime(2016, 3, 29, 6, 34, 38, 309299)}
Tue, 29 Mar 2016 14:41:30 _legacy.py[line:154] CRITICAL Unhandled error in Deferred:
Tue, 29 Mar 2016 14:41:30 _legacy.py[line:154] CRITICAL 
Tue, 29 Mar 2016 14:42:47 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 14:42:59 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 8590,
 'downloader/request_count': 26,
 'downloader/request_method_count/GET': 26,
 'downloader/response_bytes': 617915,
 'downloader/response_count': 26,
 'downloader/response_status_count/200': 26,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 6, 42, 59, 553371),
 'log_count/DEBUG': 27,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 26,
 'scheduler/dequeued/redis': 26,
 'scheduler/enqueued/redis': 26,
 'spider_exceptions/IndexError': 2,
 'start_time': datetime.datetime(2016, 3, 29, 6, 42, 47, 630253)}
Tue, 29 Mar 2016 14:49:01 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 14:49:15 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 8959,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 654955,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 6, 49, 15, 524196),
 'log_count/DEBUG': 28,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 27,
 'scheduler/dequeued/redis': 27,
 'scheduler/enqueued/redis': 27,
 'spider_exceptions/IndexError': 2,
 'start_time': datetime.datetime(2016, 3, 29, 6, 49, 1, 962774)}
Tue, 29 Mar 2016 15:00:13 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:00:45 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 18072,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 1254757,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 0, 45, 710000),
 'log_count/DEBUG': 53,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued/redis': 52,
 'scheduler/enqueued/redis': 52,
 'spider_exceptions/IndexError': 4,
 'start_time': datetime.datetime(2016, 3, 29, 7, 0, 13, 47340)}
Tue, 29 Mar 2016 15:08:36 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:08:38 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17185,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 8, 38, 476217),
 'log_count/DEBUG': 2,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2016, 3, 29, 7, 8, 36, 704543)}
Tue, 29 Mar 2016 15:09:17 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:09:19 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17185,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 9, 19, 182161),
 'log_count/DEBUG': 2,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2016, 3, 29, 7, 9, 17, 261210)}
Tue, 29 Mar 2016 15:09:33 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:09:34 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17185,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 9, 34, 973484),
 'log_count/DEBUG': 2,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2016, 3, 29, 7, 9, 33, 877947)}
Tue, 29 Mar 2016 15:10:35 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:10:51 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 18072,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 1254757,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 10, 51, 417119),
 'log_count/DEBUG': 53,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued/redis': 52,
 'scheduler/enqueued/redis': 52,
 'spider_exceptions/IndexError': 4,
 'start_time': datetime.datetime(2016, 3, 29, 7, 10, 35, 141687)}
Tue, 29 Mar 2016 15:14:15 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:14:16 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17185,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 14, 16, 820483),
 'log_count/DEBUG': 2,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2016, 3, 29, 7, 14, 15, 701371)}
Tue, 29 Mar 2016 15:14:48 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:15:55 logstats.py[line:47] INFO Crawled 39 pages (at 39 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:16:37 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 18479,
 'downloader/request_count': 53,
 'downloader/request_method_count/GET': 53,
 'downloader/response_bytes': 1254757,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 16, 37, 153746),
 'log_count/DEBUG': 54,
 'log_count/INFO': 2,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued/redis': 53,
 'scheduler/enqueued/redis': 53,
 'spider_exceptions/IndexError': 4,
 'start_time': datetime.datetime(2016, 3, 29, 7, 14, 48, 892462)}
Tue, 29 Mar 2016 15:34:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:35:05 logstats.py[line:47] INFO Crawled 27 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:35:59 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 19205,
 'downloader/request_count': 55,
 'downloader/request_method_count/GET': 55,
 'downloader/response_bytes': 1254641,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 35, 59, 744910),
 'log_count/DEBUG': 56,
 'log_count/INFO': 2,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued/redis': 55,
 'scheduler/enqueued/redis': 55,
 'spider_exceptions/IndexError': 4,
 'start_time': datetime.datetime(2016, 3, 29, 7, 34, 5, 59695)}
Tue, 29 Mar 2016 15:55:59 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 15:56:00 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 251,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 17185,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 7, 56, 0, 408099),
 'log_count/DEBUG': 2,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2016, 3, 29, 7, 55, 59, 323659)}
Tue, 29 Mar 2016 15:59:41 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 16:04:33 _legacy.py[line:154] CRITICAL Unhandled error in Deferred:
Tue, 29 Mar 2016 16:04:33 _legacy.py[line:154] CRITICAL 
Tue, 29 Mar 2016 16:04:49 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Tue, 29 Mar 2016 16:05:05 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 18072,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 1254757,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 3, 29, 8, 5, 5, 890877),
 'log_count/DEBUG': 53,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued/redis': 52,
 'scheduler/enqueued/redis': 52,
 'spider_exceptions/IndexError': 4,
 'start_time': datetime.datetime(2016, 3, 29, 8, 4, 49, 934831)}
