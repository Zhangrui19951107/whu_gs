Fri, 04 Dec 2015 10:00:13 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:00:18 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 24412,
 'downloader/request_count': 82,
 'downloader/request_method_count/GET': 82,
 'downloader/response_bytes': 829368,
 'downloader/response_count': 82,
 'downloader/response_status_count/200': 82,
 'dupefilter/filtered': 61,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 0, 18, 784898),
 'log_count/DEBUG': 84,
 'log_count/INFO': 1,
 'request_depth_max': 4,
 'response_received_count': 82,
 'scheduler/dequeued': 82,
 'scheduler/dequeued/memory': 82,
 'scheduler/enqueued': 82,
 'scheduler/enqueued/memory': 82,
 'spider_exceptions/UnboundLocalError': 49,
 'start_time': datetime.datetime(2015, 12, 4, 2, 0, 13, 125485)}
Fri, 04 Dec 2015 10:03:31 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:03:36 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 24129,
 'downloader/request_count': 81,
 'downloader/request_method_count/GET': 81,
 'downloader/response_bytes': 823105,
 'downloader/response_count': 81,
 'downloader/response_status_count/200': 81,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 3, 36, 671000),
 'log_count/DEBUG': 82,
 'log_count/INFO': 1,
 'request_depth_max': 4,
 'response_received_count': 81,
 'scheduler/dequeued': 81,
 'scheduler/dequeued/memory': 81,
 'scheduler/enqueued': 81,
 'scheduler/enqueued/memory': 81,
 'spider_exceptions/UnboundLocalError': 49,
 'start_time': datetime.datetime(2015, 12, 4, 2, 3, 31, 274490)}
Fri, 04 Dec 2015 10:04:36 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:04:41 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 24412,
 'downloader/request_count': 82,
 'downloader/request_method_count/GET': 82,
 'downloader/response_bytes': 835777,
 'downloader/response_count': 82,
 'downloader/response_status_count/200': 82,
 'dupefilter/filtered': 61,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 4, 41, 652275),
 'log_count/DEBUG': 84,
 'log_count/INFO': 1,
 'request_depth_max': 4,
 'response_received_count': 82,
 'scheduler/dequeued': 82,
 'scheduler/dequeued/memory': 82,
 'scheduler/enqueued': 82,
 'scheduler/enqueued/memory': 82,
 'spider_exceptions/UnboundLocalError': 49,
 'start_time': datetime.datetime(2015, 12, 4, 2, 4, 36, 175653)}
Fri, 04 Dec 2015 10:23:17 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:23:18 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 23, 18, 962986),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 23, 17, 865056)}
Fri, 04 Dec 2015 10:24:30 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:26:24 logstats.py[line:47] INFO Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:26:24 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 26, 24, 275145),
 'log_count/DEBUG': 3,
 'log_count/INFO': 2,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 24, 30, 968767)}
Fri, 04 Dec 2015 10:26:39 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:27:08 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 27, 8, 554101),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 26, 39, 752056)}
Fri, 04 Dec 2015 10:27:17 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:27:42 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 27, 42, 87296),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 27, 17, 529867)}
Fri, 04 Dec 2015 10:34:38 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:35:39 logstats.py[line:47] INFO Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:35:39 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 35, 39, 872354),
 'log_count/DEBUG': 3,
 'log_count/INFO': 2,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 34, 38, 79328)}
Fri, 04 Dec 2015 10:35:48 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:36:33 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 36, 33, 709996),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 35, 48, 232402)}
Fri, 04 Dec 2015 10:36:44 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:38:31 logstats.py[line:47] INFO Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:38:31 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 38, 31, 647709),
 'log_count/DEBUG': 3,
 'log_count/INFO': 2,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/AttributeError': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 36, 44, 957728)}
Fri, 04 Dec 2015 10:38:41 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:45:17 logstats.py[line:47] INFO Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:45:17 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 45, 17, 350815),
 'log_count/DEBUG': 3,
 'log_count/INFO': 2,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 38, 41, 787365)}
Fri, 04 Dec 2015 10:45:26 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:46:19 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 46, 19, 410071),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 45, 26, 961178)}
Fri, 04 Dec 2015 10:53:00 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:53:51 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 53, 51, 847561),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 53, 0, 409058)}
Fri, 04 Dec 2015 10:55:17 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:55:46 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 885,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 59271,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 55, 46, 261359),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 55, 17, 225995)}
Fri, 04 Dec 2015 10:57:11 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:58:46 logstats.py[line:47] INFO Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 10:58:54 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 568,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 30402,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 2, 58, 54, 822746),
 'log_count/DEBUG': 3,
 'log_count/INFO': 2,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 2, 57, 11, 948931)}
Fri, 04 Dec 2015 11:01:02 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:01:07 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 23792,
 'downloader/request_count': 80,
 'downloader/request_method_count/GET': 80,
 'downloader/response_bytes': 817351,
 'downloader/response_count': 80,
 'downloader/response_status_count/200': 80,
 'dupefilter/filtered': 61,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 1, 7, 988660),
 'log_count/DEBUG': 82,
 'log_count/INFO': 1,
 'request_depth_max': 4,
 'response_received_count': 80,
 'scheduler/dequeued': 80,
 'scheduler/dequeued/memory': 80,
 'scheduler/enqueued': 80,
 'scheduler/enqueued/memory': 80,
 'spider_exceptions/UnboundLocalError': 50,
 'start_time': datetime.datetime(2015, 12, 4, 3, 1, 2, 590867)}
Fri, 04 Dec 2015 11:01:44 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:02:46 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:03:47 logstats.py[line:47] INFO Crawled 216 pages (at 216 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:04:15 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 113940,
 'downloader/request_count': 314,
 'downloader/request_method_count/GET': 314,
 'downloader/response_bytes': 11205550,
 'downloader/response_count': 314,
 'downloader/response_status_count/200': 314,
 'dupefilter/filtered': 75,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 4, 15, 570700),
 'log_count/DEBUG': 317,
 'log_count/INFO': 2,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 15,
 'response_received_count': 314,
 'scheduler/dequeued': 314,
 'scheduler/dequeued/memory': 314,
 'scheduler/enqueued': 314,
 'scheduler/enqueued/memory': 314,
 'spider_exceptions/AttributeError': 3,
 'start_time': datetime.datetime(2015, 12, 4, 3, 2, 46, 617333)}
Fri, 04 Dec 2015 11:07:23 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:07:24 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10128,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 7, 24, 228264),
 'log_count/DEBUG': 3,
 'log_count/INFO': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 7, 23, 940354)}
Fri, 04 Dec 2015 11:19:35 logstats.py[line:47] INFO Crawled 11 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:19:45 logstats.py[line:47] INFO Crawled 23 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:20:04 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 2,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 24677,
 'downloader/request_count': 83,
 'downloader/request_method_count/GET': 83,
 'downloader/response_bytes': 818409,
 'downloader/response_count': 80,
 'downloader/response_status_count/200': 80,
 'dupefilter/filtered': 61,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 20, 4, 293293),
 'log_count/DEBUG': 85,
 'log_count/INFO': 3,
 'request_depth_max': 4,
 'response_received_count': 80,
 'scheduler/dequeued': 83,
 'scheduler/dequeued/memory': 83,
 'scheduler/enqueued': 83,
 'scheduler/enqueued/memory': 83,
 'spider_exceptions/UnboundLocalError': 50,
 'start_time': datetime.datetime(2015, 12, 4, 3, 1, 44, 661187)}
Fri, 04 Dec 2015 11:20:18 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:20:20 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10100,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 20, 20, 221377),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 20, 18, 418390)}
Fri, 04 Dec 2015 11:20:47 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:21:19 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 21, 19, 695746),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 20, 47, 467677)}
Fri, 04 Dec 2015 11:22:32 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:22:32 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10075,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 22, 32, 425346),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 22, 32, 194638)}
Fri, 04 Dec 2015 11:22:46 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:22:47 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 22, 47, 194872),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 22, 46, 892020)}
Fri, 04 Dec 2015 11:23:12 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:23:37 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 23, 37, 355044),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 23, 12, 108525)}
Fri, 04 Dec 2015 11:23:45 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:23:46 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 23, 46, 505325),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 23, 45, 729937)}
Fri, 04 Dec 2015 11:24:27 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:24:28 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10074,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 24, 28, 222525),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 24, 27, 472329)}
Fri, 04 Dec 2015 11:25:11 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:25:12 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10080,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 25, 12, 148033),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 25, 11, 376769)}
Fri, 04 Dec 2015 11:26:29 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:26:29 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10081,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 26, 29, 910652),
 'log_count/DEBUG': 4,
 'log_count/INFO': 1,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 26, 29, 682017)}
Fri, 04 Dec 2015 11:26:58 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:37:27 logstats.py[line:47] INFO Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:37:27 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 229,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10081,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 37, 27, 951954),
 'log_count/DEBUG': 4,
 'log_count/INFO': 2,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 26, 58, 398620)}
Fri, 04 Dec 2015 11:37:54 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:37:56 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 4519,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 308354,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 37, 56, 472741),
 'log_count/DEBUG': 18,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/AttributeError': 15,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 37, 54, 520554)}
Fri, 04 Dec 2015 11:38:11 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:40:41 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:42:59 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:44:05 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:45:29 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:47:52 logstats.py[line:47] INFO Crawled 11 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:48:02 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 4519,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 308588,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 48, 2, 451539),
 'log_count/DEBUG': 18,
 'log_count/INFO': 2,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/IndexError': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 45, 29, 325972)}
Fri, 04 Dec 2015 11:49:58 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:50:00 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 4519,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 307090,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 50, 0, 187227),
 'log_count/DEBUG': 18,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/IndexError': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 49, 58, 256808)}
Fri, 04 Dec 2015 11:51:49 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:51:51 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 4519,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 307110,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 51, 51, 333390),
 'log_count/DEBUG': 18,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/IndexError': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 3, 51, 49, 311760)}
Fri, 04 Dec 2015 11:52:07 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 11:52:21 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 18080,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 1407419,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 3, 52, 21, 76455),
 'log_count/DEBUG': 53,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued': 52,
 'scheduler/dequeued/memory': 52,
 'scheduler/enqueued': 52,
 'scheduler/enqueued/memory': 52,
 'start_time': datetime.datetime(2015, 12, 4, 3, 52, 7, 375100)}
Fri, 04 Dec 2015 12:00:18 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 12:00:26 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 8590,
 'downloader/request_count': 26,
 'downloader/request_method_count/GET': 26,
 'downloader/response_bytes': 789353,
 'downloader/response_count': 26,
 'downloader/response_status_count/200': 26,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 4, 0, 26, 756817),
 'log_count/DEBUG': 27,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 26,
 'scheduler/dequeued': 26,
 'scheduler/dequeued/memory': 26,
 'scheduler/enqueued': 26,
 'scheduler/enqueued/memory': 26,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 4, 0, 18, 595565)}
Fri, 04 Dec 2015 12:00:53 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 12:01:06 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 18072,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 1407477,
 'downloader/response_count': 52,
 'downloader/response_status_count/200': 52,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 4, 1, 6, 874049),
 'log_count/DEBUG': 53,
 'log_count/INFO': 1,
 'request_depth_max': 2,
 'response_received_count': 52,
 'scheduler/dequeued': 52,
 'scheduler/dequeued/memory': 52,
 'scheduler/enqueued': 52,
 'scheduler/enqueued/memory': 52,
 'spider_exceptions/IndexError': 3,
 'start_time': datetime.datetime(2015, 12, 4, 4, 0, 53, 816104)}
Fri, 04 Dec 2015 14:24:45 logstats.py[line:47] INFO Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
Fri, 04 Dec 2015 14:24:56 statscollectors.py[line:47] INFO Dumping Scrapy stats:
{'downloader/request_bytes': 4519,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 300205,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 12, 4, 6, 24, 56, 304749),
 'log_count/DEBUG': 18,
 'log_count/INFO': 1,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/IndexError': 4,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2015, 12, 4, 6, 24, 45, 212061)}
